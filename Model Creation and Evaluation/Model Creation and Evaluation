#    Model Creation and Evaluation:   
-   Now that the redundant or irrelevant features are removed, next step would be to select an appropriate using the selected features
>   **Split the data**
-   Train/ Test/ Validation
-   Stratified Split
-   Cross-Validation
-   Stratified K-Fold CV
-   ShuffleSplit and Stratified Shuffle Split

>   **Model selection**
-   Choose appropriate model based on the problem statement
-   **Linear Models (_Supervised learning models_)**
    -   Linear regression
    -   Logistic regression
    -   Ridge regression
    -   Lasso regression
-   **Tree-based models (_Supervised learning models_)**
    -   Decision Tree models
    -   Random Forest models
    -   Gradient Boosting Regression
    -   XGBoost
    -   LightGBM Regressor
-   **Clustering models (_Unsupervised learning models_)**
    -   K means
    -   Hierarchical clustering
    -   Gaussian Mixture models

>   **Model evaluation metrics**
-   Confusion Matrix
-   Accuracy, Precision, Recall and F1 Score
-   ROC and AUC curve 
-   Gain and Lift 
-   Confidence Interval
-   Chi Square
-   Gini Coefficient
-   Root Mean Square Error (_RMSE_), Mean Absolute Error (_MAE_), 
-   Cross Validation (_Leave-p out, k-fold, Holdout, Leave one out)_
-   Predictive Power

>   **Hyper-parameter Tuning**
-   To yield an optimal model with best set of **Hyper parameters** for optimal results

    >   **Traditional methods**
    -   GridSearchCV
    -   RandomizedSearchCV

    >   **Advanced methods**
    -   Bayesian
    -   Early Stopping
    -   Evolutionary
    -   Optuna
    -   Sampling
    -   Pruning
    -   Genetic Algorithms